{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af230c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- aoi\\n-- faces\\n-- identification\\n\\n- input\\n-- tracking.csv\\n-- faces.csv\\n-- metadata.csv\\n\\n-----\\nidentification_num = 35 / (번호)_(나이)_(성별)_(정서)\\nfaces_num = 49 / (번호)_(나이)_(성별)_(정서)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- aoi\n",
    "-- faces\n",
    "-- identification\n",
    "\n",
    "- input\n",
    "-- tracking.csv\n",
    "-- faces.csv\n",
    "-- metadata.csv\n",
    "\n",
    "-----\n",
    "identification_num = 35 / (번호)_(나이)_(성별)_(정서)\n",
    "faces_num = 49 / (번호)_(나이)_(성별)_(정서)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f38fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 접근 위한 라이브러리\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 데이터 처리 위한 라이브러리\n",
    "import pandas as pd\n",
    "# faces_aoi_converter 에서 나오는 오류 안나오게 하기 위한 코드입니다.\n",
    "# 기능에는 이상 없으니 걱정 안해도 됩니다.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "# px2deg, smoothing 위한 라이브러리\n",
    "import math\n",
    "from scipy.signal import savgol_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8cac862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "결측치 처리를 위한 함수들입니다.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def gap_fill_in(coordinate_data):\n",
    "    \"\"\"\n",
    "    ts(ms) = timestamp\n",
    "    x(px) = x coordinate\n",
    "    y(px) = y coordinate\n",
    "    max_gap_length(ms) = the duration between a last valid point before the gap and a last point in the gap\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    trial = np.array(coordinate_data['trial'])\n",
    "    module = np.array(coordinate_data['module'])\n",
    "    ts = np.array(coordinate_data['timestamp'])\n",
    "    x = np.array(coordinate_data['x'])\n",
    "    y = np.array(coordinate_data['y'])\n",
    "    \n",
    "    max_gap_length = 300\n",
    "    \n",
    "    nan_index = np.argwhere(np.isnan(x))\n",
    "    continuous_gap = False\n",
    "    gaps = []\n",
    "    temp_gap = []\n",
    "\n",
    "    for i in nan_index:\n",
    "        \n",
    "        # continuous_gap이 trial 변화 구간을 포함한 경우, 보정 불가, Gap으로 판단하지 않음\n",
    "        if continuous_gap == True and trial[i] != trial[i+1]:\n",
    "            continuous_gap = False\n",
    "            temp_gap = []\n",
    "            \n",
    "        # continuous_gap 정상 종료\n",
    "        elif continuous_gap == True and (i+1) not in nan_index:\n",
    "            continuous_gap = False\n",
    "            temp_gap.append(i)\n",
    "            gaps.append(temp_gap)\n",
    "            temp_gap = []\n",
    "            \n",
    "        # continuous_gap 정상 지속\n",
    "        elif continuous_gap == True and (i+1) in nan_index:\n",
    "            temp_gap.append(i)\n",
    "            \n",
    "        # gap의 시작이 첫 index인 경우 보정할 수 없음.. 또한 이후 두개의 elif문에서 i-1를 예외 처리 없게 쓰기위해서 먼저 분리하여 추가\n",
    "        elif continuous_gap == False and i == 0:\n",
    "            continue;\n",
    "            \n",
    "        # gap의 시작이 각 trial에 첫 index인 경우 보정할 수 없음..\n",
    "        elif continuous_gap == False and continuous_gap == False and trial[i] != trial[i-1]:\n",
    "            continue;   \n",
    "        \n",
    "       # gap의 시작 전 데이터가 NaN인 경우, 바로 위 Case에서 연속된 경우 역시 보정할 수 없음\n",
    "        elif continuous_gap == False and continuous_gap == False and (i-1) in nan_index:\n",
    "            continue;  \n",
    "            \n",
    "        # continuous_gap 정상 시작\n",
    "        elif continuous_gap == False and (i+1) in nan_index and trial[i] == trial[i+1]:\n",
    "            continuous_gap = True\n",
    "            temp_gap.append(i)\n",
    "            \n",
    "        # gap 1개인 경우, 시작과 동시에 종료\n",
    "        elif continuous_gap == False and (i+1) not in nan_index and trial[i] == trial[i+1]:\n",
    "            temp_gap.append(i)\n",
    "            gaps.append(temp_gap)\n",
    "            temp_gap = []\n",
    "            \n",
    "    for gap in gaps:\n",
    "        if (ts[np.max(gap)] - ts[np.min(gap)-1]) < max_gap_length:\n",
    "            cor_data_x =[\n",
    "                [ts[np.max(gap)+1], x[np.max(gap)+1]],\n",
    "                [ts[np.min(gap)-1], x[np.min(gap)-1]],\n",
    "            ]\n",
    "            cor_data_y = [\n",
    "                [ts[np.max(gap)+1], y[np.max(gap)+1]],\n",
    "                [ts[np.min(gap)-1], y[np.min(gap)-1]],\n",
    "            ]\n",
    "            for index in gap:\n",
    "                x[index] = linear_interpolation(cor_data_x, ts[index])\n",
    "                y[index] = linear_interpolation(cor_data_y, ts[index])\n",
    "    \n",
    "    coordinate_data = {\n",
    "        'timestamp': ts,\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'trial': trial,\n",
    "        'module': module\n",
    "    }    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(coordinate_data)\n",
    "\n",
    "def linear_interpolation(data, target_x):\n",
    "    \"\"\"\n",
    "    The gap is filled by utilizing linear_interpolation function.\n",
    "    This is the basic way to interpolate missing data.\n",
    "\n",
    "    data = list([data_x_1, data_y_1], [data_x_2, data_y_2])\n",
    "    target_x = x from missing value\n",
    "    \"\"\"\n",
    "    target_y = ((data[0][1] - data[1][1]) \\\n",
    "                / (data[0][0] - data[1][0])) \\\n",
    "                * (target_x - data[1][0]) + data[1][1]\n",
    "    \n",
    "    return target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24585353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fixation feature 추출을 위한 함수들입니다.\n",
    "\n",
    "coordinate_data = dict()\n",
    "coordinate_data[0:3] = list()\n",
    "\"\"\"\n",
    "\n",
    "def pass_sav_gol_filter(coordinate_data):\n",
    "    \"\"\"\n",
    "    X와 Y 좌표에 sav_gol filter를 적용하는 함수입니다.\n",
    "    자세한 내용은 다음 document 참고해주시기 바랍니다.\n",
    "    5와 3은 제가 가장 적절한 값으로 선택해서 넣어놨는데,\n",
    "    나중에 데이터 만지시면서 더 적합하다고 판단되는 값 있으면 넣으시면 되겠습니다.\n",
    "    \n",
    "    Document = https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.savgol_filter.html\n",
    "    \"\"\"\n",
    "    \n",
    "    coordinate_data['X'] = savgol_filter(coordinate_data['X'], 5, 3)\n",
    "    coordinate_data['Y'] = savgol_filter(coordinate_data['Y'], 5, 3)\n",
    "\n",
    "    return coordinate_data\n",
    "\n",
    "def get_angular_velocity(coordinate_data, px2deg):\n",
    "    \"\"\"\n",
    "    좌표 데이터를 각속도 데이터로 바꾸는 함수입니다.\n",
    "    각속도 데이터를 np.array 형태로 return 합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = coordinate_data['X']\n",
    "    y = coordinate_data['Y']\n",
    "    ts = coordinate_data['Timestamp']\n",
    "    velocity = np.array([np.NaN])\n",
    "\n",
    "    for i in range(len(x)-1):\n",
    "        degree = px2deg *  math.sqrt(((x[i+1] - x[i]) ** 2) + ((y[i+1] - y[i]) ** 2))\n",
    "\n",
    "        velocity = np.append(\n",
    "            velocity,\n",
    "            \n",
    "            (degree / (ts[i+1] - ts[i]) * 1000)\n",
    "        )\n",
    "\n",
    "    return velocity\n",
    "\n",
    "def classify_events(velocity_data, velocity_threshold = 30):\n",
    "    \"\"\"\n",
    "    각속도를 입력 받아서 velocity_threshold를 기준으로 움직임을 분류해 인덱스를 리턴합니다.\n",
    "    \"\"\"\n",
    "    velocity_threshold = velocity_threshold\n",
    "    # For adaptive velocity_threshold\n",
    "    # velocity_threshold = find_adaptive_threshold(velocity_data, velocity_threshold)\n",
    "\n",
    "    saccades = np.where(velocity_data > velocity_threshold)[0]\n",
    "    fixations = np.where(velocity_data <= velocity_threshold)[0]\n",
    "    blinks = np.where(np.isnan(velocity_data))[0][1:]\n",
    "\n",
    "    events = {'saccades': saccades,\n",
    "              'fixations': fixations,\n",
    "              'blinks': blinks}\n",
    "\n",
    "# 예시: events = {'saccades': [...], 'fixations': [1, 2, 3, 5, 7, 8], ...}\n",
    "    for event_key, event in events.items():\n",
    "\n",
    "        start_index = -1\n",
    "        end_index = -1\n",
    "        temp_result = []\n",
    "        result = []\n",
    "# 'fixations': [1, 2, 3, 5, 7, 8]\n",
    "        for i in range(len(event)):\n",
    "            # 마지막 인덱스에 있는 숫자(8)가 아닐 때 도는 조건문입니다.\n",
    "            if i != (len(event) - 1):\n",
    "                # 현재 인덱스와 다음 인덱스의 차이가 1이고, start_index가 디폴트일 때는\n",
    "                # fixation이 처음 시작하는 인덱스라는 의미이므로, 해당 index를 start_index에 저장합니다.\n",
    "                # ex. 1, 7\n",
    "                if ((event[i] + 1) == event[i+1]) and (start_index == -1):\n",
    "                    start_index = i\n",
    "                # 현재 인덱스와 다음 인덱스의 차이가 1이고, start_index가 디폴트가 아닐 때는\n",
    "                # fixation이 이미 시작됐고, 현재 인덱스는 이어지는 인덱스이기 때문에 계속 이어갑니다.\n",
    "                # ex. 2\n",
    "                elif ((event[i] + 1) == event[i+1]) and (start_index != -1):\n",
    "                    continue\n",
    "                # 현재 인덱스와 다음 인덱스의 차이가 1이 이상이고, start_index가 디폴트가 아닐 때는\n",
    "                # fixation이 끝난 지점이기 때문에, end_index에 값을 저장하고 result에 인덱스들을 저장합니다.\n",
    "                # ex. 3\n",
    "                elif ((event[i] + 1) != event[i+1]) and (start_index != -1):\n",
    "                    end_index = i+1\n",
    "                    temp_result = event[start_index: end_index]\n",
    "                    result.append(temp_result)\n",
    "                    start_index = -1\n",
    "                    end_index = -1\n",
    "                    temp_result = []\n",
    "                # 현재 인덱스와 다음 인덱스의 차이가 1 이상이며, start_index가 디폴트가 아니므로\n",
    "                # fixation이 시작과 동시에 끝나는 지점입니다. 바로 result에 넣습니다.\n",
    "                # ex. 5\n",
    "                elif ((event[i] + 1) != event[i+1]) and (start_index == -1):\n",
    "                    result.append([event[i]])\n",
    "            # 마지막 인덱스에 있는 숫자일 경우 도는 조건문입니다.\n",
    "            else:\n",
    "                # start_index가 디폴트라면, 마지막 인덱스이면서 fixation이 시작하는 지점입니다.\n",
    "                # 시작과 동시에 종료되므로 바로 result에 넣어줍니다.\n",
    "                # ex. fixation = [1,2,3,5]일 때, 5에 해당함.\n",
    "                if start_index == -1:\n",
    "                    result.append([event[i]])\n",
    "                # 이전의 값과 1 차이가 나고 start_index가 디폴트가 아니기 때문에\n",
    "                # 이전부터 이어진 fixation index이고, 마지막 인덱스이므로 종료되어야 합니다.\n",
    "                # 그러므로 현재의 start_index부터 마지막까지 index를 result에 append합니다.\n",
    "                # ex. 8\n",
    "                elif (start_index != -1) and ((event[i] - 1) == event[i - 1]):\n",
    "                    end_index = i\n",
    "                    result.append(event[start_index:])\n",
    "\n",
    "        events[event_key] = result\n",
    "\n",
    "    return events\n",
    "\n",
    "# For adaptive velocity threshold\n",
    "def update_threshold(velocity_data, threshold):\n",
    "    \"\"\"\n",
    "    각속도 역치 값을 찾는 함수에서 사용되는 함수입니다.\n",
    "    velocity_data의 평균 값과 표준편차를 이용해서 최적의 velocity 값을 찾아갑니다.\n",
    "    다만, velocity_data의 길이가 짧을 경우(시간 span이 짧을 경우) 제대로 작동하지 않습니다.\n",
    "    따라서, 충분히 데이터가 모인 뒤에 사용해볼 것을 권장합니다.\n",
    "    \"\"\"\n",
    "    velocity_below_threshold = velocity_data[np.where(velocity_data < threshold)]\n",
    "    mean = velocity_below_threshold.mean()\n",
    "    std = velocity_below_threshold.std()\n",
    "    updated_threshold = mean + (std * 6)\n",
    "\n",
    "    return updated_threshold\n",
    "\n",
    "def find_adaptive_threshold(velocity_data, threshold):\n",
    "    \"\"\"\n",
    "    update_threshold 함수를 recursive하게 사용해서 최적의 값을 찾습니다.\n",
    "    threshold 값을 리턴합니다.\n",
    "    \"\"\"\n",
    "    while abs(update_threshold(velocity_data, threshold) - threshold) > 1:\n",
    "        threshold = update_threshold(velocity_data, threshold)\n",
    "    return threshold\n",
    "\n",
    "def get_classification_result(coordinate_data, velocity_data):\n",
    "    \"\"\"\n",
    "    classify_events() 함수에서 return한 인덱스 값을 input으로 받습니다.\n",
    "    분류된 인덱스를 이용해 시간을 계산합니다.\n",
    "    label, start_time, end_time, duration, start_x, start_y, end_x, end_y를 리턴합니다.\n",
    "    \"\"\"\n",
    "    result = classify_events(velocity_data)\n",
    "    timestamp, x, y = coordinate_data['Timestamp'], coordinate_data['X'], coordinate_data['Y']\n",
    "    output = []\n",
    "    for key, value in result.items():\n",
    "        for i in value:\n",
    "            start_time = timestamp[i[0]-1]\n",
    "            end_time = timestamp[i[-1]]\n",
    "            start_x = x[i[0]-1]\n",
    "            end_x = x[i[-1]]\n",
    "            start_y = y[i[0]-1]\n",
    "            end_y = y[i[-1]]\n",
    "            output.append([key, start_time, end_time, (end_time-start_time), start_x, start_y, end_x, end_y])\n",
    "    df_output = pd.DataFrame(data = output,\n",
    "                             columns = ['label', 'start_time', 'end_time', 'duration', 'start_x', 'start_y', 'end_x', 'end_y'])\n",
    "    df_output.sort_values(by=['start_time'], axis=0, inplace=True)\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67715201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input(input_file_name):\n",
    "    temp_data = pd.read_csv(input_dir + '\\\\{}'.format(input_file_name))\n",
    "\n",
    "    return temp_data\n",
    "\n",
    "def get_identification_fixation(trial_result, item, identification_aoi):\n",
    "    eye_x_aoi_1 = (trial_result[\"start_x\"] >= identification_aoi.at[\"{}_eye\".format(item), 'x1'])\n",
    "    eye_x_aoi_2 = (trial_result[\"start_x\"] <= identification_aoi.at[\"{}_eye\".format(item), 'x2'])\n",
    "\n",
    "    eye_x_aoi = (eye_x_aoi_1 & eye_x_aoi_2)\n",
    "\n",
    "    eye_y_aoi_1 = (trial_result[\"start_y\"] >= identification_aoi.at[\"{}_eye\".format(item), 'y1'])\n",
    "    eye_y_aoi_2 = (trial_result[\"start_y\"] <= identification_aoi.at[\"{}_eye\".format(item), 'y2'])\n",
    "\n",
    "    eye_y_aoi = (eye_y_aoi_1 & eye_y_aoi_2)\n",
    "\n",
    "    mouth_x_aoi_1 = (trial_result[\"start_x\"] >= identification_aoi.at[\"{}_mouth\".format(item), 'x1'])\n",
    "    mouth_x_aoi_2 = (trial_result[\"start_x\"] <= identification_aoi.at[\"{}_mouth\".format(item), 'x2'])\n",
    "\n",
    "    mouth_x_aoi = (mouth_x_aoi_1 & mouth_x_aoi_2)\n",
    "\n",
    "    mouth_y_aoi_1 = (trial_result[\"start_y\"] >= identification_aoi.at[\"{}_mouth\".format(item), 'y1'])\n",
    "    mouth_y_aoi_2 = (trial_result[\"start_y\"] <= identification_aoi.at[\"{}_mouth\".format(item), 'y2'])\n",
    "\n",
    "    mouth_y_aoi = (mouth_y_aoi_1 & mouth_y_aoi_2)\n",
    "\n",
    "    fixation_in_eye_aoi = trial_result[eye_x_aoi & eye_y_aoi]\n",
    "    fixation_in_mouth_aoi = trial_result[mouth_x_aoi & mouth_y_aoi]\n",
    "\n",
    "    return fixation_in_eye_aoi, fixation_in_mouth_aoi\n",
    "\n",
    "def get_faces_fixation(trial_result, faces_aoi):\n",
    "    face11_x_aoi = ((trial_result[\"start_x\"] > faces_aoi.at['faces_11', 'x1']) & (trial_result[\"start_x\"] < faces_aoi.at['faces_11', 'x2']))\n",
    "    face11_y_aoi = ((trial_result[\"start_y\"] > faces_aoi.at['faces_11', 'y1']) & (trial_result[\"start_y\"] < faces_aoi.at['faces_11', 'y2']))\n",
    "\n",
    "    face12_x_aoi = ((trial_result[\"start_x\"] > faces_aoi.at['faces_12', 'x1']) & (trial_result[\"start_x\"] < faces_aoi.at['faces_12', 'x2']))\n",
    "    face12_y_aoi = ((trial_result[\"start_y\"] > faces_aoi.at['faces_12', 'y1']) & (trial_result[\"start_y\"] < faces_aoi.at['faces_12', 'y2']))\n",
    "\n",
    "    face21_x_aoi = ((trial_result[\"start_x\"] > faces_aoi.at['faces_21', 'x1']) & (trial_result[\"start_x\"] < faces_aoi.at['faces_21', 'x2']))\n",
    "    face21_y_aoi = ((trial_result[\"start_y\"] > faces_aoi.at['faces_21', 'y1']) & (trial_result[\"start_y\"] < faces_aoi.at['faces_21', 'y2']))\n",
    "\n",
    "    face22_x_aoi = ((trial_result[\"start_x\"] > faces_aoi.at['faces_22', 'x1']) & (trial_result[\"start_x\"] < faces_aoi.at['faces_22', 'x2']))\n",
    "    face22_y_aoi = ((trial_result[\"start_y\"] > faces_aoi.at['faces_22', 'y1']) & (trial_result[\"start_y\"] < faces_aoi.at['faces_22', 'y2']))\n",
    "\n",
    "    total_fixation = trial_result.label.count()\n",
    "    face11_fixation = trial_result[face11_x_aoi & face11_y_aoi].label.count()\n",
    "    face12_fixation = trial_result[face12_x_aoi & face12_y_aoi].label.count()\n",
    "    face21_fixation = trial_result[face21_x_aoi & face21_y_aoi].label.count()\n",
    "    face22_fixation = trial_result[face22_x_aoi & face22_y_aoi].label.count()\n",
    "\n",
    "    return total_fixation, face11_fixation, face12_fixation, face21_fixation, face22_fixation\n",
    "\n",
    "def extract_identification_dwell_time(tracking_data, item, identification_aoi):\n",
    "    trial_duration = max(tracking_data['timestamp'])\n",
    "    all_point_in_trial = tracking_data.shape[0]    \n",
    "\n",
    "    eye_x_aoi_1 = (tracking_data[\"x\"] >= identification_aoi.at[\"{}_eye\".format(item), 'x1'])\n",
    "    eye_x_aoi_2 = (tracking_data[\"x\"] <= identification_aoi.at[\"{}_eye\".format(item), 'x2'])\n",
    "\n",
    "    eye_x_aoi = eye_x_aoi_1 & eye_x_aoi_2\n",
    "\n",
    "    eye_y_aoi_1 = (tracking_data[\"y\"] >= identification_aoi.at[\"{}_eye\".format(item), 'y1'])\n",
    "    eye_y_aoi_2 = (tracking_data[\"y\"] <= identification_aoi.at[\"{}_eye\".format(item), 'y2'])\n",
    "\n",
    "    eye_y_aoi = eye_y_aoi_1 & eye_y_aoi_2\n",
    "\n",
    "    mouth_x_aoi_1 = (tracking_data[\"x\"] >= identification_aoi.at[\"{}_mouth\".format(item), 'x1'])\n",
    "    mouth_x_aoi_2 = (tracking_data[\"x\"] <= identification_aoi.at[\"{}_mouth\".format(item), 'x2'])\n",
    "\n",
    "    mouth_x_aoi = mouth_x_aoi_1 & mouth_x_aoi_2\n",
    "\n",
    "    mouth_y_aoi_1 = (tracking_data[\"y\"] >= identification_aoi.at[\"{}_mouth\".format(item), 'y1'])\n",
    "    mouth_y_aoi_2 = (tracking_data[\"y\"] <= identification_aoi.at[\"{}_mouth\".format(item), 'y2'])\n",
    "\n",
    "    mouth_y_aoi = mouth_y_aoi_1 & mouth_y_aoi_2\n",
    "\n",
    "    point_in_eye_aoi = tracking_data[eye_x_aoi & eye_y_aoi]\n",
    "    point_in_mouth_aoi = tracking_data[mouth_x_aoi & mouth_y_aoi]\n",
    "\n",
    "    abs_dwell_time_eyes = len(point_in_eye_aoi) / all_point_in_trial * trial_duration\n",
    "    abs_dwell_time_mouth = len(point_in_mouth_aoi) / all_point_in_trial * trial_duration\n",
    "\n",
    "    try:\n",
    "        first_time_eye = tracking_data[eye_x_aoi & eye_y_aoi].iat[0,4]\n",
    "    except:\n",
    "        first_time_eye = np.nan\n",
    "\n",
    "    return abs_dwell_time_eyes, abs_dwell_time_mouth, first_time_eye\n",
    "\n",
    "def extract_faces_dwelltime(trial_tracking_data, faces_aoi):\n",
    "\n",
    "    trial_duration = max(trial_tracking_data['timestamp'])\n",
    "    all_point_in_trial = trial_tracking_data.shape[0]   \n",
    "\n",
    "    face11_x_aoi = (trial_tracking_data[\"x\"] > faces_aoi.at['faces_11', 'x1']) & (trial_tracking_data[\"x\"] < faces_aoi.at['faces_11', 'x2'])\n",
    "    face11_y_aoi = (trial_tracking_data[\"y\"] > faces_aoi.at['faces_11', 'y1']) & (trial_tracking_data[\"y\"] < faces_aoi.at['faces_11', 'y2'])\n",
    "\n",
    "    face12_x_aoi = (trial_tracking_data[\"x\"] > faces_aoi.at['faces_12', 'x1']) & (trial_tracking_data[\"x\"] < faces_aoi.at['faces_12', 'x2'])\n",
    "    face12_y_aoi = (trial_tracking_data[\"y\"] > faces_aoi.at['faces_12', 'y1']) & (trial_tracking_data[\"y\"] < faces_aoi.at['faces_12', 'y2'])\n",
    "\n",
    "    face21_x_aoi = (trial_tracking_data[\"x\"] > faces_aoi.at['faces_21', 'x1']) & (trial_tracking_data[\"x\"] < faces_aoi.at['faces_21', 'x2'])\n",
    "    face21_y_aoi = (trial_tracking_data[\"y\"] > faces_aoi.at['faces_21', 'y1']) & (trial_tracking_data[\"y\"] < faces_aoi.at['faces_21', 'y2'])\n",
    "\n",
    "    face22_x_aoi = (trial_tracking_data[\"x\"] > faces_aoi.at['faces_22', 'x1']) & (trial_tracking_data[\"x\"] < faces_aoi.at['faces_22', 'x2'])\n",
    "    face22_y_aoi = (trial_tracking_data[\"y\"] > faces_aoi.at['faces_22', 'y1']) & (trial_tracking_data[\"y\"] < faces_aoi.at['faces_22', 'y2'])\n",
    "\n",
    "    point_in_face11_aoi = trial_tracking_data[face11_x_aoi & face11_y_aoi]\n",
    "    point_in_face12_aoi = trial_tracking_data[face12_x_aoi & face12_y_aoi]\n",
    "    point_in_face21_aoi = trial_tracking_data[face21_x_aoi & face21_y_aoi]\n",
    "    point_in_face22_aoi = trial_tracking_data[face22_x_aoi & face22_y_aoi]\n",
    "\n",
    "    abs_dwell_time_face11 = len(point_in_face11_aoi) / all_point_in_trial * trial_duration\n",
    "    abs_dwell_time_face12 = len(point_in_face12_aoi) / all_point_in_trial * trial_duration\n",
    "    abs_dwell_time_face21 = len(point_in_face21_aoi) / all_point_in_trial * trial_duration\n",
    "    abs_dwell_time_face22 = len(point_in_face22_aoi) / all_point_in_trial * trial_duration\n",
    "\n",
    "    return abs_dwell_time_face11, abs_dwell_time_face12, abs_dwell_time_face21, abs_dwell_time_face22\n",
    "\n",
    "def get_index_of(emotion, faces_trial_to_item):\n",
    "    result = pd.melt(faces_trial_to_item.loc[:, 'face11':'face22']).value.str.split(\"_\").str[-1] == emotion\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "화면 크기에 따라 AOI 영역을 보정해주는 코드입니다.\n",
    "\"\"\"\n",
    "def identification_aoi_converter(screen_height_resolution, screen_width_resolution, identification_aoi):\n",
    "    a_screen_height_resolution = 1080\n",
    "    a_screen_width_resolution = 1920\n",
    "    b_screen_height_resolution = screen_height_resolution\n",
    "    b_screen_width_resolution = screen_width_resolution\n",
    "\n",
    "    resolution_ratio = b_screen_height_resolution / a_screen_height_resolution\n",
    "\n",
    "    identification_aoi.y1 = identification_aoi.y1 * resolution_ratio\n",
    "    identification_aoi.y2 = identification_aoi.y2 * resolution_ratio\n",
    "    identification_aoi.x1 = (b_screen_width_resolution / 2) - (((a_screen_width_resolution / 2) - identification_aoi.x1) * resolution_ratio)\n",
    "    identification_aoi.x2 = (b_screen_width_resolution / 2) + ((identification_aoi.x2 - (a_screen_width_resolution / 2)) * resolution_ratio)\n",
    "    \n",
    "    return identification_aoi\n",
    "\n",
    "def faces_aoi_converter(screen_height_resolution, screen_width_resolution, faces_aoi):\n",
    "    \n",
    "    a_screen_height_resolution = 1080\n",
    "    a_screen_width_resolution = 1920\n",
    "    b_screen_height_resolution = screen_height_resolution\n",
    "    b_screen_width_resolution = screen_width_resolution\n",
    "\n",
    "    resolution_ratio = b_screen_height_resolution / a_screen_height_resolution\n",
    "\n",
    "    faces_aoi.y1 = faces_aoi.y1 * resolution_ratio\n",
    "    faces_aoi.y2 = faces_aoi.y2 * resolution_ratio\n",
    "    faces_aoi.x1.faces_11 = (b_screen_width_resolution / 2) - (((a_screen_width_resolution / 2) - faces_aoi.x1.faces_11) * resolution_ratio)\n",
    "    faces_aoi.x2.faces_11 = (b_screen_width_resolution / 2) - (((a_screen_width_resolution / 2) - faces_aoi.x2.faces_11) * resolution_ratio)\n",
    "    faces_aoi.x1.faces_12 = (b_screen_width_resolution / 2) + ((faces_aoi.x1.faces_12 - (a_screen_width_resolution / 2)) * resolution_ratio)\n",
    "    faces_aoi.x2.faces_12 = (b_screen_width_resolution / 2) + ((faces_aoi.x2.faces_12 - (a_screen_width_resolution / 2)) * resolution_ratio)\n",
    "    faces_aoi.x1.faces_21 = (b_screen_width_resolution / 2) - (((a_screen_width_resolution / 2) - faces_aoi.x1.faces_21) * resolution_ratio)\n",
    "    faces_aoi.x2.faces_21 = (b_screen_width_resolution / 2) - (((a_screen_width_resolution / 2) - faces_aoi.x2.faces_21) * resolution_ratio)\n",
    "    faces_aoi.x1.faces_22 = (b_screen_width_resolution / 2) + ((faces_aoi.x1.faces_22 - (a_screen_width_resolution / 2)) * resolution_ratio)\n",
    "    faces_aoi.x2.faces_22 = (b_screen_width_resolution / 2) + ((faces_aoi.x2.faces_22 - (a_screen_width_resolution / 2)) * resolution_ratio)\n",
    "    \n",
    "    return faces_aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1934715d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# institute = 'kirbs'\n",
    "# date = '220623'\n",
    "# pid = '00000000'\n",
    "\n",
    "def get_result(institute, date, pid):\n",
    "    \n",
    "    # 경로 설정 및 파일 불러오기\n",
    "    current_dir = os.getcwd()\n",
    "    institute = institute\n",
    "    date = date\n",
    "    pid = pid\n",
    "    identification_trial_to_item = pd.read_csv(current_dir + \"\\\\{}_{}\\\\input\\\\identification\\\\{}_{}_{}_identification.csv\".format(institute, date, institute, date, pid))\n",
    "    faces_trial_to_item = pd.read_csv(current_dir + \"\\\\{}_{}\\\\input\\\\faces\\\\{}_{}_{}_faces.csv\".format(institute, date, institute, date, pid), index_col = 'trial')\n",
    "    meta_data = pd.read_csv(current_dir + \"\\\\{}_{}\\\\input\\\\metadata\\\\{}_{}_{}_metadata.csv\".format(institute, date, institute, date, pid))\n",
    "    tracking_data = pd.read_csv(current_dir + \"\\\\{}_{}\\\\input\\\\tracking\\\\{}_{}_{}_tracking.csv\".format(institute, date, institute, date, pid))\n",
    "    identification_aoi = pd.read_csv(current_dir + \"\\\\{}_{}\\\\aoi\\\\identification.csv\".format(institute, date), index_col = 'item')\n",
    "    faces_aoi = pd.read_csv(current_dir + \"\\\\{}_{}\\\\aoi\\\\faces.csv\".format(institute, date), index_col = 'item')\n",
    "    \n",
    "    # eye tracking 결측치 처리\n",
    "    # 수정 필요, trial당 gap_fill_in함수로 처리 예정\n",
    "    # tracking_data = tracking_data.fillna(method='ffill')\n",
    "    \n",
    "    tracking_data = gap_fill_in(tracking_data)\n",
    "\n",
    "    \n",
    "    # px2deg 계산에 필요한 변수를 선언하겠습니다.\n",
    "    screen_size = meta_data.screen_size[0]\n",
    "    distance = meta_data.distance[0]\n",
    "    screen_height_resolution = meta_data.screen_height_resolution[0]\n",
    "    screen_width_resolution = meta_data.screen_width_resolution[0]\n",
    "\n",
    "    # px2deg 계산\n",
    "    px2deg = math.degrees(math.atan2(0.5 * screen_size, distance)) / (0.5 * screen_height_resolution)\n",
    "    \n",
    "    # AOI를 피험자의 해상도에 맞게 변경해주겠습니다.\n",
    "    identification_aoi = identification_aoi_converter(screen_height_resolution, screen_width_resolution, identification_aoi)\n",
    "    faces_aoi = faces_aoi_converter(screen_height_resolution, screen_width_resolution, faces_aoi)\n",
    "    \n",
    "    # return 파일 선언\n",
    "    identification_result = pd.DataFrame(columns = [\n",
    "        'pid',            \n",
    "        'module',\n",
    "        'trial',\n",
    "        'item',\n",
    "        'total_fixation',\n",
    "        'eye_fixation',\n",
    "        'mouth_fixation',\n",
    "        'abs_dwell_time_eyes',\n",
    "        'abs_dwell_time_mouth',\n",
    "        'first_time_eye'])\n",
    "\n",
    "    faces_result = pd.DataFrame(columns = [\n",
    "        'pid',\n",
    "        'module',\n",
    "        'trial',\n",
    "        'total_fixation',\n",
    "        'face11_fixation',\n",
    "        'face12_fixation',\n",
    "        'face21_fixation',\n",
    "        'face22_fixation',\n",
    "        'total_fixation_under1000',\n",
    "        'face11_fixation_under1000',\n",
    "        'face12_fixation_under1000',\n",
    "        'face21_fixation_under1000',\n",
    "        'face22_fixation_under1000',\n",
    "        'total_fixation_over1000',\n",
    "        'face11_fixation_over1000',\n",
    "        'face12_fixation_over1000',\n",
    "        'face21_fixation_over1000',\n",
    "        'face22_fixation_over1000',\n",
    "        'abs_dwell_time_face11',\n",
    "        'abs_dwell_time_face12',\n",
    "        'abs_dwell_time_face21',\n",
    "        'abs_dwell_time_face22',\n",
    "        'abs_dwell_time_face11_under1000',\n",
    "        'abs_dwell_time_face12_under1000',\n",
    "        'abs_dwell_time_face21_under1000',\n",
    "        'abs_dwell_time_face22_under1000',\n",
    "        'abs_dwell_time_face11_over1000',\n",
    "        'abs_dwell_time_face12_over1000',\n",
    "        'abs_dwell_time_face21_over1000',\n",
    "        'abs_dwell_time_face22_over1000'])\n",
    "    \n",
    "    \n",
    "    # identification 데이터 처리 코드입니다.\n",
    "    identification_tracking_data = tracking_data[tracking_data.module == \"identification\"]\n",
    "    for trial in identification_tracking_data.trial.unique():\n",
    "        item = identification_trial_to_item.at[trial, 'item']\n",
    "        identification_trial_tracking_data = identification_tracking_data[identification_tracking_data.trial == trial]\n",
    "        identification_trial_tracking_data = identification_trial_tracking_data.drop_duplicates(['timestamp', 'module', 'trial'], keep = 'last').reset_index().copy()\n",
    "\n",
    "        ts = np.array(identification_trial_tracking_data.timestamp)\n",
    "        x = np.array(identification_trial_tracking_data.x)\n",
    "        y = np.array(identification_trial_tracking_data.y)\n",
    "\n",
    "        identification_trial_dict = {'Timestamp': ts,\n",
    "                                    'X' : x,\n",
    "                                    'Y' : y}\n",
    "\n",
    "        identification_trial_dict = pass_sav_gol_filter(identification_trial_dict)\n",
    "        velocity = get_angular_velocity(identification_trial_dict, px2deg)\n",
    "        identification_trial_result = get_classification_result(identification_trial_dict, velocity)\n",
    "        identification_trial_result = identification_trial_result[identification_trial_result.label == 'fixations']\n",
    "\n",
    "        fixation_in_eye_aoi, fixation_in_mouth_aoi = get_identification_fixation(identification_trial_result, item, identification_aoi)\n",
    "\n",
    "        abs_dwell_time_eyes, abs_dwell_time_mouth, first_time_eye = extract_identification_dwell_time(identification_trial_tracking_data, item, identification_aoi)\n",
    "\n",
    "        total_fixation = identification_trial_result.label.count()\n",
    "        eye_fixation = fixation_in_eye_aoi.label.count()\n",
    "        mouth_fixation = fixation_in_mouth_aoi.label.count()\n",
    "\n",
    "        temp_df = pd.DataFrame({\n",
    "                'pid': pid,\n",
    "                'module': 'identification',\n",
    "                'trial': trial,\n",
    "                'item': item,\n",
    "                'total_fixation': total_fixation,\n",
    "                'eye_fixation': eye_fixation,\n",
    "                'mouth_fixation': mouth_fixation,\n",
    "                'abs_dwell_time_eyes': abs_dwell_time_eyes,\n",
    "                'abs_dwell_time_mouth': abs_dwell_time_mouth,\n",
    "                'first_time_eye': first_time_eye}, index=[0])\n",
    "\n",
    "        identification_result = pd.concat([identification_result, temp_df])\n",
    "    identification_result = identification_result.reset_index(drop = True)\n",
    " \n",
    "\n",
    "    \n",
    "    total_fixation_mean = identification_result['total_fixation'].sum()/len(identification_result)\n",
    "    eye_fixation_mean = identification_result['eye_fixation'].sum()/len(identification_result)\n",
    "    mouth_fixation_mean = identification_result['mouth_fixation'].sum()/len(identification_result)\n",
    "    abs_dwell_time_eyes_mean = identification_result['abs_dwell_time_eyes'].sum()/len(identification_result)\n",
    "    abs_dwell_time_mouth_mean = identification_result['abs_dwell_time_mouth'].sum()/len(identification_result)\n",
    "\n",
    "    identification_result_mean = pd.DataFrame({\n",
    "                                    'pid': pid,\n",
    "                                    'total_fixation_mean': total_fixation_mean,\n",
    "                                    'eye_fixation_mean': eye_fixation_mean,\n",
    "                                    'mouth_fixation_mean': mouth_fixation_mean,\n",
    "                                    'abs_dwell_time_eyes_mean': abs_dwell_time_eyes_mean,\n",
    "                                    'abs_dwell_time_mouth_mean': abs_dwell_time_mouth_mean}, index=[0])\n",
    "                                   \n",
    "    \n",
    "    \n",
    "# faces 데이터 처리 코드입니다.\n",
    "\n",
    "    faces_tracking_data = tracking_data[tracking_data.module == 'faces']\n",
    "    for trial in faces_tracking_data.trial.unique():\n",
    "        # 각 trial의 모든 시간 데이터 분석\n",
    "        faces_trial_tracking_data = faces_tracking_data[faces_tracking_data.trial == trial]\n",
    "        faces_trial_tracking_data = faces_trial_tracking_data.drop_duplicates(['timestamp', 'module', 'trial'], keep = 'last').reset_index().copy()\n",
    "\n",
    "        ts = np.array(faces_trial_tracking_data.timestamp)\n",
    "        x = np.array(faces_trial_tracking_data.x)\n",
    "        y = np.array(faces_trial_tracking_data.y)\n",
    "\n",
    "        faces_trial_dict = {'Timestamp': ts,\n",
    "                                    'X' : x,\n",
    "                                    'Y' : y}\n",
    "\n",
    "        faces_trial_dict = pass_sav_gol_filter(faces_trial_dict)\n",
    "        velocity = get_angular_velocity(faces_trial_dict, px2deg)\n",
    "        faces_trial_result = get_classification_result(faces_trial_dict, velocity)\n",
    "        faces_trial_result = faces_trial_result[faces_trial_result.label == 'fixations']\n",
    "\n",
    "        # 각 trial의 앞 1초만 데이터 분석\n",
    "\n",
    "        faces_trial_tracking_data_under1000 = faces_trial_tracking_data[faces_trial_tracking_data.timestamp <= 1000]\n",
    "        ts_under1000 = np.array(faces_trial_tracking_data_under1000.timestamp)\n",
    "        x_under1000 = np.array(faces_trial_tracking_data_under1000.x)\n",
    "        y_under1000 = np.array(faces_trial_tracking_data_under1000.y)\n",
    "\n",
    "        faces_trial_dict_under1000 = {'Timestamp': ts_under1000,\n",
    "                                        'X' : x_under1000,\n",
    "                                        'Y' : y_under1000}\n",
    "\n",
    "        faces_trial_dict_under1000 = pass_sav_gol_filter(faces_trial_dict_under1000)\n",
    "        velocity_under1000 = get_angular_velocity(faces_trial_dict_under1000, px2deg)\n",
    "        faces_trial_result_under1000 = get_classification_result(faces_trial_dict_under1000, velocity_under1000)\n",
    "        faces_trial_result_under1000 = faces_trial_result_under1000[faces_trial_result_under1000.label == 'fixations']\n",
    "        \n",
    "        \n",
    "        # 각 trial의 1~5초 데이터 분석\n",
    "\n",
    "        faces_trial_tracking_data_over1000 = faces_trial_tracking_data[faces_trial_tracking_data.timestamp > 1000]\n",
    "        ts_over1000 = np.array(faces_trial_tracking_data_over1000.timestamp)\n",
    "        x_over1000 = np.array(faces_trial_tracking_data_over1000.x)\n",
    "        y_over1000 = np.array(faces_trial_tracking_data_over1000.y)\n",
    "\n",
    "        faces_trial_dict_over1000 = {'Timestamp': ts_over1000,\n",
    "                                        'X' : x_over1000,\n",
    "                                        'Y' : y_over1000}\n",
    "\n",
    "        faces_trial_dict_over1000 = pass_sav_gol_filter(faces_trial_dict_over1000)\n",
    "        velocity_over1000 = get_angular_velocity(faces_trial_dict_over1000, px2deg)\n",
    "        faces_trial_result_over1000 = get_classification_result(faces_trial_dict_over1000, velocity_over1000)\n",
    "        faces_trial_result_over1000 = faces_trial_result_over1000[faces_trial_result_over1000.label == 'fixations']\n",
    "       \n",
    "    \n",
    "        # 첫 1초 동안 AOI 내에 들어온 Fixation 찾는 코드\n",
    "        total_fixation_under1000, face11_fixation_under1000, \\\n",
    "        face12_fixation_under1000, face21_fixation_under1000, face22_fixation_under1000 =\\\n",
    "        get_faces_fixation(faces_trial_result_under1000, faces_aoi)\n",
    "\n",
    "        \n",
    "        # 1~5초 동안 AOI 내에 들어온 Fixation 찾는 코드\n",
    "        total_fixation_over1000, face11_fixation_over1000, \\\n",
    "        face12_fixation_over1000, face21_fixation_over1000, face22_fixation_over1000 =\\\n",
    "        get_faces_fixation(faces_trial_result_over1000, faces_aoi)\n",
    "        \n",
    "        \n",
    "        # 자극 시간 전체에 걸쳐 AOI 내에 들어온 Fixation 코드\n",
    "        total_fixation, face11_fixation, face12_fixation, face21_fixation, face22_fixation =\\\n",
    "        get_faces_fixation(faces_trial_result, faces_aoi)\n",
    "\n",
    "        \n",
    "        # 자극 시간 전체에 걸쳐 AOI 내에 들어온 dwelltime 코드\n",
    "        abs_dwell_time_face11, abs_dwell_time_face12, \\\n",
    "        abs_dwell_time_face21, abs_dwell_time_face22 =\\\n",
    "        extract_faces_dwelltime(faces_trial_tracking_data, faces_aoi)\n",
    "        \n",
    "        # 첫 1초 동안 AOI 내에 들어온 dwelltime 코드\n",
    "        abs_dwell_time_face11_under1000, abs_dwell_time_face12_under1000, \\\n",
    "        abs_dwell_time_face21_under1000, abs_dwell_time_face22_under1000 =\\\n",
    "        extract_faces_dwelltime(faces_trial_tracking_data[faces_trial_tracking_data.timestamp <= 1000], faces_aoi)\n",
    "        \n",
    "        # 1~5초 동안 AOI 내에 들어온 dwelltime 코드\n",
    "        abs_dwell_time_face11_over1000, abs_dwell_time_face12_over1000, \\\n",
    "        abs_dwell_time_face21_over1000, abs_dwell_time_face22_over1000 =\\\n",
    "        extract_faces_dwelltime(faces_trial_tracking_data[faces_trial_tracking_data.timestamp > 1000], faces_aoi)\n",
    "\n",
    "        temp_df = pd.DataFrame({\n",
    "                'pid': pid,\n",
    "                'module': 'faces',\n",
    "                'trial': trial,\n",
    "                'total_fixation': total_fixation,\n",
    "                'face11_fixation': face11_fixation,\n",
    "                'face12_fixation': face12_fixation,\n",
    "                'face21_fixation': face21_fixation,\n",
    "                'face22_fixation': face22_fixation,\n",
    "                'total_fixation_under1000': total_fixation_under1000,\n",
    "                'face11_fixation_under1000': face11_fixation_under1000,\n",
    "                'face12_fixation_under1000': face12_fixation_under1000,\n",
    "                'face21_fixation_under1000': face21_fixation_under1000,\n",
    "                'face22_fixation_under1000': face22_fixation_under1000,\n",
    "                'total_fixation_over1000': total_fixation_over1000,\n",
    "                'face11_fixation_over1000': face11_fixation_over1000,\n",
    "                'face12_fixation_over1000': face12_fixation_over1000,\n",
    "                'face21_fixation_over1000': face21_fixation_over1000,\n",
    "                'face22_fixation_over1000': face22_fixation_over1000,\n",
    "                'abs_dwell_time_face11': abs_dwell_time_face11,\n",
    "                'abs_dwell_time_face12': abs_dwell_time_face12,\n",
    "                'abs_dwell_time_face21': abs_dwell_time_face21,\n",
    "                'abs_dwell_time_face22': abs_dwell_time_face22,\n",
    "                'abs_dwell_time_face11_under1000': abs_dwell_time_face11_under1000,\n",
    "                'abs_dwell_time_face12_under1000': abs_dwell_time_face12_under1000,\n",
    "                'abs_dwell_time_face21_under1000': abs_dwell_time_face21_under1000,\n",
    "                'abs_dwell_time_face22_under1000': abs_dwell_time_face22_under1000,\n",
    "                'abs_dwell_time_face11_over1000': abs_dwell_time_face11_over1000,\n",
    "                'abs_dwell_time_face12_over1000': abs_dwell_time_face12_over1000,\n",
    "                'abs_dwell_time_face21_over1000': abs_dwell_time_face21_over1000,\n",
    "                'abs_dwell_time_face22_over1000': abs_dwell_time_face22_over1000}, index = [0])\n",
    "\n",
    "        faces_result = pd.concat([faces_result, temp_df])\n",
    "    faces_result = faces_result.reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Faces 결과를 각 정서마다의 fixation의 합, dwelltime의 합으로 변환하는 코드입니다.\n",
    "    \n",
    "    # 정서 종류를 설정합니다.\n",
    "    emotions = ['neutral', 'happy', 'sad', 'angry']\n",
    "\n",
    "    # 응시자의 각 trial의 정서를 true, false 값으로 변환합니다.\n",
    "    # emotion_index는 7개의 key를 가지고 len = 49의 value를 가지는 딕셔너리 값입니다.\n",
    "    emotion_index = {}\n",
    "\n",
    "    for emotion in emotions:\n",
    "        emotion_index[emotion] = get_index_of(emotion,faces_trial_to_item)\n",
    "\n",
    "    # dict 자료형인 emotion_index를 dataframe으로 만들어줍시다.\n",
    "    emotion_index_df = pd.concat(emotion_index, axis=1)\n",
    "\n",
    "    # emotion_index와 faces_result의 값을 곱할 것입니다.\n",
    "    # faces_result에서 fixation, fixation_under1000, dwelltime 데이터 프레임을 만들어줍시다.\n",
    "    fixation_series = pd.melt(faces_result.loc[:, 'face11_fixation': 'face22_fixation']).value\n",
    "    fixation_df = pd.concat([fixation_series]*4, axis=1)\n",
    "    fixation_df.columns = ['neutral', 'happy', 'sad', 'angry']\n",
    "\n",
    "    fixation_under1000_series = pd.melt(faces_result.loc[:, 'face11_fixation_under1000': 'face22_fixation_under1000']).value\n",
    "    fixation_under1000_df = pd.concat([fixation_under1000_series]*4, axis=1)\n",
    "    fixation_under1000_df.columns = ['neutral', 'happy', 'sad', 'angry']\n",
    "    \n",
    "    fixation_over1000_series = pd.melt(faces_result.loc[:, 'face11_fixation_over1000': 'face22_fixation_over1000']).value\n",
    "    fixation_over1000_df = pd.concat([fixation_over1000_series]*4, axis=1)\n",
    "    fixation_over1000_df.columns = ['neutral', 'happy', 'sad', 'angry']\n",
    "\n",
    "    dwelltime_series = pd.melt(faces_result.loc[:, 'abs_dwell_time_face11': 'abs_dwell_time_face22']).value\n",
    "    dwelltime_df = pd.concat([dwelltime_series]*4, axis=1)\n",
    "    dwelltime_df.columns = ['neutral', 'happy', 'sad', 'angry']\n",
    "    \n",
    "    dwelltime_under1000_series = pd.melt(faces_result.loc[:, 'abs_dwell_time_face11_under1000': 'abs_dwell_time_face22_under1000']).value\n",
    "    dwelltime_under1000_df = pd.concat([dwelltime_under1000_series]*4, axis=1)\n",
    "    dwelltime_under1000_df.columns = ['neutral', 'happy', 'sad', 'angry']\n",
    "    \n",
    "    dwelltime_over1000_series = pd.melt(faces_result.loc[:, 'abs_dwell_time_face11_over1000': 'abs_dwell_time_face22_over1000']).value\n",
    "    dwelltime_over1000_df = pd.concat([dwelltime_over1000_series]*4, axis=1)\n",
    "    dwelltime_over1000_df.columns = ['neutral', 'happy', 'sad', 'angry']\n",
    "\n",
    "    # emotion_index와 각 feature별 df를 곱해줍시다.\n",
    "    emotion_fixation_df = emotion_index_df.mul(fixation_df, axis = 0)\n",
    "    emotion_fixation_under1000_df = emotion_index_df.mul(fixation_under1000_df, axis = 0)\n",
    "    emotion_fixation_over1000_df = emotion_index_df.mul(fixation_over1000_df, axis = 0)\n",
    "\n",
    "    emotion_dwelltime_df = emotion_index_df.mul(dwelltime_df, axis = 0)\n",
    "    emotion_dwelltime_under1000_df = emotion_index_df.mul(dwelltime_under1000_df, axis = 0)\n",
    "    emotion_dwelltime_over1000_df = emotion_index_df.mul(dwelltime_over1000_df, axis = 0)\n",
    "\n",
    "    # 이제 각 정서별 feature의 합을 구해봅시다.\n",
    "    faces_emotion_sum_result = {'fixation' : emotion_fixation_df.sum(),\n",
    "                         'fixation_under1000' : emotion_fixation_under1000_df.sum(),\n",
    "                         'fixation_over1000' : emotion_fixation_over1000_df.sum(),\n",
    "                         'dwelltime' : emotion_dwelltime_df.sum(),\n",
    "                         'dwelltime_under1000' : emotion_dwelltime_under1000_df.sum(),\n",
    "                         'dwelltime_over1000' : emotion_dwelltime_over1000_df.sum()}\n",
    "\n",
    "    # 보기 편하게 행열을 바꿔줍니다.\n",
    "    faces_emotion_sum_result = pd.DataFrame(faces_emotion_sum_result).transpose()\n",
    "\n",
    "\n",
    "    # 1*24 데이터프레임으로 변환, 평균값으로 변환\n",
    "    neutral_fixation_mean = faces_emotion_sum_result.at['fixation', 'neutral']/len(faces_trial_to_item[faces_trial_to_item['q']=='neutral'])\n",
    "    neutral_fixation_under1000_mean = faces_emotion_sum_result.at['fixation_under1000', 'neutral']/len(faces_trial_to_item[faces_trial_to_item['q']=='neutral'])\n",
    "    neutral_fixation_over1000_mean = faces_emotion_sum_result.at['fixation_over1000', 'neutral']/len(faces_trial_to_item[faces_trial_to_item['q']=='neutral'])\n",
    "    neutral_dwelltime_mean = faces_emotion_sum_result.at['dwelltime', 'neutral']/len(faces_trial_to_item[faces_trial_to_item['q']=='neutral'])\n",
    "    neutral_dwelltime_under1000_mean = faces_emotion_sum_result.at['dwelltime_under1000', 'neutral']/len(faces_trial_to_item[faces_trial_to_item['q']=='neutral'])\n",
    "    neutral_dwelltime_over1000_mean = faces_emotion_sum_result.at['dwelltime_over1000', 'neutral']/len(faces_trial_to_item[faces_trial_to_item['q']=='neutral'])\n",
    "\n",
    "    happy_fixation_mean = faces_emotion_sum_result.at['fixation', 'happy']/len(faces_trial_to_item[faces_trial_to_item['q']=='happy'])\n",
    "    happy_fixation_under1000_mean = faces_emotion_sum_result.at['fixation_under1000', 'happy']/len(faces_trial_to_item[faces_trial_to_item['q']=='happy'])\n",
    "    happy_fixation_over1000_mean = faces_emotion_sum_result.at['fixation_over1000', 'happy']/len(faces_trial_to_item[faces_trial_to_item['q']=='happy'])\n",
    "    happy_dwelltime_mean = faces_emotion_sum_result.at['dwelltime', 'happy']/len(faces_trial_to_item[faces_trial_to_item['q']=='happy'])\n",
    "    happy_dwelltime_under1000_mean = faces_emotion_sum_result.at['dwelltime_under1000', 'happy']/len(faces_trial_to_item[faces_trial_to_item['q']=='happy'])\n",
    "    happy_dwelltime_over1000_mean = faces_emotion_sum_result.at['dwelltime_over1000', 'happy']/len(faces_trial_to_item[faces_trial_to_item['q']=='happy'])\n",
    "\n",
    "    sad_fixation_mean = faces_emotion_sum_result.at['fixation', 'sad']/len(faces_trial_to_item[faces_trial_to_item['q']=='sad'])\n",
    "    sad_fixation_under1000_mean = faces_emotion_sum_result.at['fixation_under1000', 'sad']/len(faces_trial_to_item[faces_trial_to_item['q']=='sad'])\n",
    "    sad_fixation_over1000_mean = faces_emotion_sum_result.at['fixation_over1000', 'sad']/len(faces_trial_to_item[faces_trial_to_item['q']=='sad'])\n",
    "    sad_dwelltime_mean = faces_emotion_sum_result.at['dwelltime', 'sad']/len(faces_trial_to_item[faces_trial_to_item['q']=='sad'])\n",
    "    sad_dwelltime_under1000_mean = faces_emotion_sum_result.at['dwelltime_under1000', 'sad']/len(faces_trial_to_item[faces_trial_to_item['q']=='sad'])\n",
    "    sad_dwelltime_over1000_mean = faces_emotion_sum_result.at['dwelltime_over1000', 'sad']/len(faces_trial_to_item[faces_trial_to_item['q']=='sad'])\n",
    "\n",
    "    angry_fixation_mean = faces_emotion_sum_result.at['fixation', 'angry']/len(faces_trial_to_item[faces_trial_to_item['q']=='angry'])\n",
    "    angry_fixation_under1000_mean = faces_emotion_sum_result.at['fixation_under1000', 'angry']/len(faces_trial_to_item[faces_trial_to_item['q']=='angry'])\n",
    "    angry_fixation_over1000_mean = faces_emotion_sum_result.at['fixation_over1000', 'angry']/len(faces_trial_to_item[faces_trial_to_item['q']=='angry'])\n",
    "    angry_dwelltime_mean = faces_emotion_sum_result.at['dwelltime', 'angry']/len(faces_trial_to_item[faces_trial_to_item['q']=='angry'])\n",
    "    angry_dwelltime_under1000_mean = faces_emotion_sum_result.at['dwelltime_under1000', 'angry']/len(faces_trial_to_item[faces_trial_to_item['q']=='angry'])\n",
    "    angry_dwelltime_over1000_mean = faces_emotion_sum_result.at['dwelltime_over1000', 'angry']/len(faces_trial_to_item[faces_trial_to_item['q']=='angry'])\n",
    "    \n",
    "    faces_emotion_result_reshape = pd.DataFrame({\n",
    "                'neutral_fixation_mean': neutral_fixation_mean,\n",
    "                'neutral_fixation_under1000_mean': neutral_fixation_under1000_mean,\n",
    "                'neutral_fixation_over1000_mean': neutral_fixation_over1000_mean,\n",
    "                'neutral_dwelltime_mean': neutral_dwelltime_mean,\n",
    "                'neutral_dwelltime_under1000_mean': neutral_dwelltime_under1000_mean,\n",
    "                'neutral_dwelltime_over1000_mean': neutral_dwelltime_over1000_mean,\n",
    "                'happy_fixation_mean': happy_fixation_mean,\n",
    "                'happy_fixation_under1000_mean': happy_fixation_under1000_mean,\n",
    "                'happy_fixation_over1000_mean': happy_fixation_over1000_mean,\n",
    "                'happy_dwelltime_mean': happy_dwelltime_mean,\n",
    "                'happy_dwelltime_under1000_mean': happy_dwelltime_under1000_mean,\n",
    "                'happy_dwelltime_over1000_mean': happy_dwelltime_over1000_mean,\n",
    "                'sad_fixation_mean': sad_fixation_mean,\n",
    "                'sad_fixation_under1000_mean': sad_fixation_under1000_mean,\n",
    "                'sad_fixation_over1000_mean': sad_fixation_over1000_mean,\n",
    "                'sad_dwelltime_mean': sad_dwelltime_mean,\n",
    "                'sad_dwelltime_under1000_mean': sad_dwelltime_under1000_mean,\n",
    "                'sad_dwelltime_over1000_mean': sad_dwelltime_over1000_mean,\n",
    "                'angry_fixation_mean': angry_fixation_mean,\n",
    "                'angry_fixation_under1000_mean': angry_fixation_under1000_mean,\n",
    "                'angry_fixation_over1000_mean': angry_fixation_over1000_mean,\n",
    "                'angry_dwelltime_mean': angry_dwelltime_mean,\n",
    "                'angry_dwelltime_under1000_mean': angry_dwelltime_under1000_mean,\n",
    "                'angry_dwelltime_over1000_mean': angry_dwelltime_over1000_mean}, index = [0])\n",
    "    \n",
    "    identification_faces_summary = pd.concat([identification_result_mean, faces_emotion_result_reshape], axis = 1)\n",
    "    \n",
    "    identification_result.to_csv(current_dir + '\\\\{}_{}\\\\output\\\\identification_result\\\\{}_{}_{}_identification_result.csv'.format(institute, date, institute, date, pid))\n",
    "    identification_result_mean.to_csv(current_dir + '\\\\{}_{}\\\\output\\\\identification_result_mean\\\\{}_{}_{}_identification_result_mean.csv'.format(institute, date, institute, date, pid))\n",
    "    faces_result.to_csv(current_dir + '\\\\{}_{}\\\\output\\\\faces_result\\\\{}_{}_{}_faces_result.csv'.format(institute, date, institute, date, pid))\n",
    "    faces_emotion_result_reshape.to_csv(current_dir + '\\\\{}_{}\\\\output\\\\faces_emotion_sum_result\\\\{}_{}_{}_faces_emotion_sum_result.csv'.format(institute, date, institute, date, pid))\n",
    "    identification_faces_summary.to_csv(current_dir + '\\\\{}_{}\\\\output\\\\summary\\\\{}_{}_{}_identification_faces_summary.csv'.format(institute, date, institute, date, pid))\n",
    "    \n",
    "    return identification_faces_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a90422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LAI(institute, date):\n",
    "    \n",
    "    institute = institute\n",
    "    date = date\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # output을 저장할 폴더를 만들어줍니다.\n",
    "    os.mkdir(current_dir + \"\\\\{}_{}\\\\output\".format(institute, date))\n",
    "    os.mkdir(current_dir + \"\\\\{}_{}\\\\output\\\\faces_result\".format(institute, date))\n",
    "    os.mkdir(current_dir + \"\\\\{}_{}\\\\output\\\\identification_result\".format(institute, date))\n",
    "    os.mkdir(current_dir + \"\\\\{}_{}\\\\output\\\\identification_result_mean\".format(institute, date))\n",
    "    os.mkdir(current_dir + \"\\\\{}_{}\\\\output\\\\faces_emotion_sum_result\".format(institute, date))\n",
    "    os.mkdir(current_dir + \"\\\\{}_{}\\\\output\\\\summary\".format(institute, date))\n",
    "\n",
    "    # input 리스트를 불러옵니다.\n",
    "    identification_trial_to_item_list = os.listdir(current_dir + \"\\\\{}_{}\\\\input\\\\identification\".format(institute, date))\n",
    "    faces_trial_to_item_list = os.listdir(current_dir + \"\\\\{}_{}\\\\input\\\\faces\".format(institute, date))\n",
    "    meta_data_list = os.listdir(current_dir + \"\\\\{}_{}\\\\input\\\\metadata\".format(institute, date))\n",
    "    tracking_data_list = os.listdir(current_dir + \"\\\\{}_{}\\\\input\\\\tracking\".format(institute, date))\n",
    "\n",
    "    # input list를 정렬해줍시다.\n",
    "    identification_trial_to_item_list.sort()\n",
    "    faces_trial_to_item_list.sort()\n",
    "    meta_data_list.sort()\n",
    "    tracking_data_list.sort()\n",
    "    \n",
    "    \n",
    "    all_summary = pd.DataFrame(columns = [\n",
    "                    'pid',\n",
    "                    'total_fixation_mean',\n",
    "                    'eye_fixation_mean',\n",
    "                    'mouth_fixation_mean',\n",
    "                    'abs_dwell_time_eyes_mean',\n",
    "                    'abs_dwell_time_mouth_mean',\n",
    "                    'neutral_fixation_mean',\n",
    "                    'neutral_fixation_under1000_mean',\n",
    "                    'neutral_fixation_over1000_mean',\n",
    "                    'neutral_dwelltime_mean',\n",
    "                    'neutral_dwelltime_under1000_mean',\n",
    "                    'neutral_dwelltime_over1000_mean',\n",
    "                    'happy_fixation_mean',\n",
    "                    'happy_fixation_under1000_mean',\n",
    "                    'happy_fixation_over1000_mean',\n",
    "                    'happy_dwelltime_mean',\n",
    "                    'happy_dwelltime_under1000_mean',\n",
    "                    'happy_dwelltime_over1000_mean',\n",
    "                    'sad_fixation_mean',\n",
    "                    'sad_fixation_under1000_mean',\n",
    "                    'sad_fixation_over1000_mean',\n",
    "                    'sad_dwelltime_mean',\n",
    "                    'sad_dwelltime_under1000_mean',\n",
    "                    'sad_dwelltime_over1000_mean',\n",
    "                    'angry_fixation_mean',\n",
    "                    'angry_fixation_under1000_mean',\n",
    "                    'angry_fixation_over1000_mean',\n",
    "                    'angry_dwelltime_mean',\n",
    "                    'angry_dwelltime_under1000_mean',\n",
    "                    'angry_dwelltime_over1000_mean'])\n",
    "    \n",
    "\n",
    "    # 총 몇 명이 응시했는지 확인해서 변수에 저장합니다.\n",
    "    overall_participant = len(meta_data_list)\n",
    "\n",
    "    # 이제 첫 번째 응시자부터 get_result 돌려줍니다.\n",
    "\n",
    "    for file_index in range(overall_participant):\n",
    "        pid = meta_data_list[file_index].split('_')[-2]\n",
    "\n",
    "        identification_faces_summary = get_result(institute, date, pid)\n",
    "        all_summary = pd.concat([all_summary, identification_faces_summary])\n",
    "    all_summary.to_csv(current_dir + '\\\\{}_{}\\\\output\\\\summary\\\\all_summary.csv'.format(institute, date), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a76045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LAI('kirbs', '220810')\n",
    "\n",
    "\n",
    "# 실행할 때마다 회사명, 실시일자를 수정해야 함\n",
    "# 여기까지 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c67d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
